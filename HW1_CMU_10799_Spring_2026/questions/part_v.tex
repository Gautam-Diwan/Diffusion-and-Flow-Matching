
\hwpart{V}{Reflection (10 points)}
Now that you have had a fully immersive experience with DDPM, let's take a step back and reflect on what we have learned so far.

\question{Reflection Questions}{10}

\subq{a}{3} Based on your experience implementing and experimenting with DDPM: What do you think DDPM is bad at? Identify 2-3 limitations you observed or suspect. These could relate to sample quality, training efficiency, sampling speed, controllability, or anything else. Be specific—connect each limitation to something concrete from your experiments or implementation.

\answerbox{}{
% Your answer here

Based on implementation and experiments, DDPM has the following key limitations:

\textbf{1. Slow Sampling Speed (most critical)}
\begin{itemize}
\item Requires 1000 reverse steps to generate a single image
\item One image takes $\sim$4 seconds on L40S GPU
\item In contrast, GANs generate images in milliseconds even though they are worse but might suffice for applications like avatar generation
\end{itemize}

\textbf{2. Training Inefficiency}
\begin{itemize}
\item Required 50k iterations for convergence on small $64 \times 64$ dataset
\item Random timestep sampling trains on all timesteps equally, despite early/late timesteps being easier/harder
\item \textit{Concrete observation:} First 10k iterations seemed to waste capacity on easy denoising tasks
\end{itemize}

\textbf{3. Limited Control Over Generated Samples}
\begin{itemize}
\item No natural way to condition on attributes beyond class labels
\item Cannot easily interpolate between generated samples in meaningful way
\item Deterministic sampling makes it hard to explore sample diversity
\item \textit{From this work:} No way to request ``a smiling woman'' or ``person with glasses'' without training separate conditional model
\end{itemize}
}
\includeanswer{q7a}

\subq{b}{3} For those limitations you identified, how do you think they could be improved? Propose at least 2 concrete ideas. These don't need to be novel—they can be things you've heard about, ideas from papers, or your own speculation. For each idea, briefly explain why you think it might help.
(We're not asking you to implement these—just to think critically about the design space.)

\answerbox{}{
% Your answer here
\textbf{1. Accelerated Sampling via Learned Schedules (DDIM / Fast Samplers)}

\begin{itemize}
\item \textbf{What:} Instead of uniform steps through all timesteps, skip steps intelligently using learned trajectories or variance-preserving jumps

\item \textbf{Why it helps:} Could reduce sampling from 1000 steps to 50--100 steps with minimal quality loss

\item \textbf{Research:} DDIM paper demonstrates this is achievable in practice
\end{itemize}

\textbf{2. Improved Training via Timestep Weighting}

\begin{itemize}
\item \textbf{What:} Weight training loss differently at different timesteps (e.g., higher weight on high-noise regions where errors matter most)

\item \textbf{Why it helps:} Current uniform weighting trains equally on easy tasks ($t=999$) and hard tasks ($t=0$). Reweighting accelerates convergence and improves sample quality
\end{itemize}

}
\includeanswer{q7b}

\subq{c}{3} What ablations or experiments are you still curious about? List 1-2 things you would explore if you had more time and compute budget. Why do these interest you?

\answerbox{}{
% Your answer here
If I had more time and budget, I would explore:

\textbf{1. Effect of Noise Schedule Design}

\begin{itemize}
\item \textbf{What to test:} Compare linear $\beta$ schedule vs. cosine schedule vs. learned schedule

\item \textbf{Why I'm curious:} DDPM implementation uses fixed linear schedules, but some papers suggest cosine (which I used) or other schedules work better

\item \textbf{My hypothesis:} Cosine schedule probably dedicates more capacity to perceptually important timesteps (mid-range noise levels)
\end{itemize}

\textbf{2. Skip Connection Design in U-Net}

\begin{itemize}
\item \textbf{What to test:} Different skip connection patterns (concat vs. add), varying attention head counts and resolutions

\item \textbf{Why I'm curious:} Current architecture uses fixed attention at $[8,16]$ resolutions, but optimal might be problem-dependent

\item \textbf{Practical value:} Understanding this could lead to better architectures for different resolutions and datasets

\item \textbf{From my implementation:} Model seems to rely heavily on skip connections; varying them systematically could reveal their importance
\end{itemize}

\textbf{3. Alternative architectures}

\begin{itemize}
\item \textbf{What to test:} Different architectures like say Transformer

\item \textbf{Why I'm curious:} U-Net requires intricate design of skip connections for preservation but transformer is more generalized and latest. We already use attention layers so why not tranformer too?

\item \textbf{Practical value:} Transformers have been shown to scale quite a lot which may help for high resolution image generation
\end{itemize}
}
\includeanswer{q7c}

\subq{d}{1} List all the resources that you found helpful for this homework. Include AI tools, open source code, tutorials, papers, classmates that helped you, etc.

\answerbox{}{
% Your answer here
\textbf{Academic \& Technical Resources:}
\begin{itemize}
\item Ho et al. (2020) -- Original DDPM paper for foundational math
\item DDIM Paper
\end{itemize}

\textbf{Code References:}
\begin{itemize}
\item DDIM Implementation: https://github.com/ermongroup/ddim/
\end{itemize}

\textbf{AI Tools \& Assistants:}
\begin{itemize}
\item Visual Studio Code + Github Copilot
\item Claude 4.5 Sonnet
\end{itemize}

\textbf{Community Resources:}
\begin{itemize}
\item CMU 10799 course materials and starter code
\item Reddit r/MachineLearning discussions on diffusion models
\item Classmate discussions with Karan Bania and Aman Chulawala
\end{itemize}
}
\includeanswer{q7d}